{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_league(n) returns a list of links to the webpages of every club within the top n European leagues.\n",
    "#i.e. Passing 1 as an argument will return links to the no.1 league in Europe- England. Passing 2 as an argument will return links of clubs in the 2 best leagues.\n",
    "def top_league(n):\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "\n",
    "    page = \"https://www.transfermarkt.co.uk/wettbewerbe/europa\"\n",
    "    pageTree = requests.get(page, headers=headers)\n",
    "    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "    links = pageSoup.find_all(\"tr\")\n",
    "\n",
    "    site = 'https://www.transfermarkt.co.uk'\n",
    "    s20_string = \"/plus/?saison_id=2020\"\n",
    "\n",
    "    top_leagues = []\n",
    "    for a in list(range(2,((n*2)+1),2)):\n",
    "        top_leagues.append((site+(str(links[a]).split('href=\"',5)[2].split('\"')[0])+s20_string))\n",
    "\n",
    "    teams = []\n",
    "\n",
    "    for a in top_leagues:\n",
    "\n",
    "        page = a\n",
    "        pageTree = requests.get(page, headers=headers)\n",
    "        pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "        links2 = pageSoup.find_all(\"a\",{\"class\":\"vereinprofil_tooltip\"})\n",
    "        site = 'https://www.transfermarkt.co.uk'\n",
    "        s21_string = \"/plus/?saison_id=2021\"\n",
    "\n",
    "        if a==\"https://www.transfermarkt.co.uk/bundesliga/startseite/wettbewerb/L1/plus/?saison_id=2020\" or a==\"https://www.transfermarkt.co.uk/liga-portugal-bwin/startseite/wettbewerb/PO1/plus/?saison_id=2020\" or a==\"'https://www.transfermarkt.co.uk/eredivisie/startseite/wettbewerb/NL1/plus/?saison_id=2020'\":\n",
    "            for b in list(range(0,(18*3),3)):\n",
    "                teams.append((site+(str(links2[b]).split('href=\"')[1].split('\">')[0])).split(\"/saison_id\")[0]+s21_string)\n",
    "        elif a== 'https://www.transfermarkt.co.uk/premier-liga/startseite/wettbewerb/RU1/plus/?saison_id=2020':\n",
    "            for b in list(range(0,(16*3),3)):\n",
    "                teams.append((site+(str(links2[b]).split('href=\"')[1].split('\">')[0])).split(\"/saison_id\")[0]+s21_string) \n",
    "        else:\n",
    "            for b in list(range(0,(20*3),3)):\n",
    "                teams.append((site+(str(links2[b]).split('href=\"')[1].split('\">')[0])).split(\"/saison_id\")[0]+s21_string)\n",
    "    return teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_league_player(n) returns a list of links to the individual profile webpage for every player participating in Europe's top n number of leagues.\n",
    "def top_league_player(n):\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "\n",
    "    page = \"https://www.transfermarkt.co.uk/wettbewerbe/europa\"\n",
    "    pageTree = requests.get(page, headers=headers)\n",
    "    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "    links = pageSoup.find_all(\"tr\")\n",
    "\n",
    "    site = 'https://www.transfermarkt.co.uk'\n",
    "    s20_string = \"/plus/?saison_id=2020\"\n",
    "\n",
    "    top_leagues = []\n",
    "    for a in list(range(2,((n*2)+1),2)):\n",
    "        top_leagues.append((site+(str(links[a]).split('href=\"',5)[2].split('\"')[0])+s20_string))\n",
    "\n",
    "    teams = []\n",
    "\n",
    "    for a in top_leagues:\n",
    "\n",
    "        page = a\n",
    "        pageTree = requests.get(page, headers=headers)\n",
    "        pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "        links2 = pageSoup.find_all(\"a\",{\"class\":\"vereinprofil_tooltip\"})\n",
    "        site = 'https://www.transfermarkt.co.uk'\n",
    "        s21_string = \"/plus/?saison_id=2021\"\n",
    "\n",
    "        if a==\"https://www.transfermarkt.co.uk/bundesliga/startseite/wettbewerb/L1/plus/?saison_id=2020\" or a==\"https://www.transfermarkt.co.uk/liga-portugal-bwin/startseite/wettbewerb/PO1/plus/?saison_id=2020\" or a==\"'https://www.transfermarkt.co.uk/eredivisie/startseite/wettbewerb/NL1/plus/?saison_id=2020'\":\n",
    "            for b in list(range(0,(18*3),3)):\n",
    "                teams.append((site+(str(links2[b]).split('href=\"')[1].split('\">')[0])).split(\"/saison_id\")[0]+s21_string)\n",
    "        elif a== 'https://www.transfermarkt.co.uk/premier-liga/startseite/wettbewerb/RU1/plus/?saison_id=2020':\n",
    "            for b in list(range(0,(16*3),3)):\n",
    "                teams.append((site+(str(links2[b]).split('href=\"')[1].split('\">')[0])).split(\"/saison_id\")[0]+s21_string) \n",
    "        else:\n",
    "            for b in list(range(0,(20*3),3)):\n",
    "                teams.append((site+(str(links2[b]).split('href=\"')[1].split('\">')[0])).split(\"/saison_id\")[0]+s21_string)\n",
    "    \n",
    "    player_links = []\n",
    "    for a in teams:\n",
    "        page = a\n",
    "        pageTree = requests.get(page, headers=headers)\n",
    "        pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "        site = 'https://www.transfermarkt.co.uk'\n",
    "\n",
    "        links = pageSoup.find_all(\"a\",{\"class\":\"spielprofil_tooltip\"})\n",
    "\n",
    "        for b in list(range(0,len(links),2)):\n",
    "            player_links.append(site+(str(links[b]).split('href=\"')[1].split('\"')[0]))\n",
    "    \n",
    "    return player_links\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contract dataframe: contract scrape from individual player pages. #DO NOT DELETE THE BELOW CELL!!!!!! IT TAKES FOREVER TO RUN but it WORKS!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1736854dadeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'User-Agent'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_league_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-2ab2cdb346b5>\u001b[0m in \u001b[0;36mtop_league_player\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mpageTree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mpageSoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpageTree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    671\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    160\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#iterating through every link in the list provided to it and then returns a dataframe of player data from the given webpages.\n",
    "#top_league_player(5) returns a list of links to the individual profile webpage for every player participating in Europe's top 5 leagues.\n",
    "\n",
    "site = 'https://www.transfermarkt.co.uk'\n",
    "PlayerList = []\n",
    "ContractList = []\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "\n",
    "for a in top_league_player(5):\n",
    "\n",
    "    page = a\n",
    "    pageTree = requests.get(page, headers=headers)\n",
    "    pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "    Player = pageSoup.find_all(\"meta\",{\"property\":\"og:title\"})\n",
    "    Contract = pageSoup.find_all(\"span\",{\"class\":\"dataValue\"})\n",
    "\n",
    "    PlayerList.append(str(Player).split('content=\"')[1].split(\" - \")[0])\n",
    "    try:\n",
    "        ContractList.append((int(str(Contract[-1]).split(\", \")[1].split(\"</span>\")[0])-2021))\n",
    "    except IndexError:\n",
    "        ContractList.append(\"fail\")\n",
    "\n",
    "contract_df = pd.DataFrame({\"Player\":PlayerList,\"Contract Years Left\":ContractList})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observing what our contract df looks like\n",
    "contract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function works when providing links of individual club pages.\n",
    "#It iterates through every link in the list provided to it and then returns a dataframe of player data from the given webpages.\n",
    "def build_df(links):\n",
    "\n",
    "    PlayersList = []\n",
    "    AgeList=[]\n",
    "    NationList=[]\n",
    "    ValuesList = []\n",
    "    PositionsList=[]\n",
    "    ClubList = []\n",
    "\n",
    "    for a in links:\n",
    "\n",
    "        headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}\n",
    "        page = a\n",
    "        pageTree = requests.get(page, headers=headers)\n",
    "        pageSoup = BeautifulSoup(pageTree.content, 'html.parser')\n",
    "\n",
    "        Players = pageSoup.find_all(\"img\", {\"class\": \"bilderrahmen-fixed lazy lazy\"})\n",
    "        Age = pageSoup.find_all(\"td\", {\"class\": \"zentriert\"})\n",
    "        Values = pageSoup.find_all(\"td\", {\"class\": \"rechts hauptlink\"})\n",
    "        Positions = pageSoup.find_all(\"td\", {\"class\": [\"zentriert rueckennummer bg_Torwart\",\"zentriert rueckennummer bg_Abwehr\",\"zentriert rueckennummer bg_Mittelfeld\",\"zentriert rueckennummer bg_Sturm\"]})\n",
    "        Nationality = pageSoup.find_all(\"td\", {\"class\": \"zentriert\"})\n",
    "        Club = pageSoup.find_all(\"meta\")\n",
    "\n",
    "        for i in range(0,len(Values)):\n",
    "            ValuesList.append(Values[i].text)\n",
    "\n",
    "        for i in range(0,len(Players)):\n",
    "            PlayersList.append(str(Players[i]).split('\" class',1)[0].split('<img alt=\"',1)[1])\n",
    "\n",
    "        for i in range(0,len(Positions)):\n",
    "            PositionsList.append(str(Positions[i]).split('title=\"',1)[1].split('\"><div')[0])\n",
    "\n",
    "        for i in range(1,(len(Players)*3),3):\n",
    "            AgeList.append(str(Age[i]).split(\"(\",1)[1].split(\")\",1)[0])\n",
    "\n",
    "        for i in range(2,(len(Players)*3),3):\n",
    "            NationList.append(str(Nationality[i]).split('title=\"',1)[1].split('\"/',1)[0])\n",
    "\n",
    "        for i in range(0,len(Players)):\n",
    "            ClubList.append(str(Club[6]).split('content=\"')[1].split(\",\")[0])\n",
    "            \n",
    "\n",
    "    #Initial uncleaned dataframe initiated\n",
    "    df= pd.DataFrame({\"Players\":PlayersList,\"Club\":ClubList,\"Position\":PositionsList, \"Age\":AgeList, \"Nationality\":NationList,\"Values\":ValuesList,})\n",
    "\n",
    "    #Missing Transfer Values were stored as '\\xa0'. The line below replaces them as None values\n",
    "    df.loc[(df.Values == '\\xa0'),'Values']= None\n",
    "\n",
    "    #Dataframe without missing transfer values\n",
    "    df_droppednull = df.dropna()\n",
    "\n",
    "    #Converting the Transfer Values data to float            \n",
    "    transfer_values = [a[1:len(a)-2] for a in df_droppednull['Values']]\n",
    "\n",
    "    cleaned_values=[]\n",
    "    for a in list(range(len(transfer_values))):\n",
    "        if transfer_values[a].endswith('m'):\n",
    "            cleaned_values.append(float(transfer_values[a][:len(transfer_values[a])-1])*1000000)\n",
    "        elif transfer_values[a].endswith('Th.'):\n",
    "            cleaned_values.append(float(transfer_values[a][:len(transfer_values[a])-3])*1000)\n",
    "        else:\n",
    "            cleaned_values.append(float(a))\n",
    "\n",
    "    #Constructing the Final Dataframe   \n",
    "    final_df= pd.DataFrame({\"Player\":df_droppednull['Players'],\"Club\":df_droppednull['Club'],\n",
    "                    \"Age\":df_droppednull['Age'],\"Position\":df_droppednull['Position'],\n",
    "                    \"Nation\":df_droppednull['Nationality'],\"Value\":cleaned_values})\n",
    "\n",
    "    #df ranked by transfer value\n",
    "    ranked_df = final_df.sort_values('Value',ascending=False)\n",
    "    \n",
    "    return ranked_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the dataframe of players from every Club Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a dataframe by scraping information of the 98 teams from Europe's top 5 leagues - i.e. England, Spain, Italy, Germany & France\n",
    "first_df = build_df(top_league(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seeing what our dataframe looks like\n",
    "first_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging our dataframe with contract information\n",
    "merged_df = pd.merge(first_df, contract_df, on='Player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping Clubs by individual Leagues and making a separate \"League\" column.\n",
    "\n",
    "England = ['Manchester City','Liverpool FC','Crystal Palace','Chelsea FC','Fulham FC','Brighton &amp; Hove Albion','West Bromwich Albion','Newcastle United','Leeds United','Aston Villa','Sheffield United','Manchester United','West Ham United','Leicester City','Tottenham Hotspur','Burnley FC','Southampton FC','Arsenal FC','Wolverhampton Wanderers','Everton FC']\n",
    "Spain = ['SD Eibar','CA Osasuna','Athletic Bilbao','Real Betis Balompié','Valencia CF','Celta de Vigo','Levante UD','Cádiz CF','FC Barcelona','Villarreal CF','SD Huesca','Sevilla FC','Getafe CF','Deportivo Alavés','Real Valladolid CF','Granada CF','Real Madrid','Elche CF','Atlético de Madrid','Real Sociedad']\n",
    "Italy = ['US Sassuolo','AC Milan','Juventus FC','Udinese Calcio','Genoa CFC','Cagliari Calcio','Inter Milan','FC Crotone','Hellas Verona','Benevento Calcio','Parma Calcio 1913','SSC Napoli','AS Roma','Bologna FC 1909','Torino FC','UC Sampdoria','SS Lazio','ACF Fiorentina','Atalanta BC','Spezia Calcio']\n",
    "Germany = ['Bayern Munich','Hertha BSC','Borussia Dortmund','VfB Stuttgart','1.FSV Mainz 05','Arminia Bielefeld','Bayer 04 Leverkusen','SV Werder Bremen','1. FC Köln','FC Augsburg','VfL Wolfsburg','TSG 1899 Hoffenheim','RB Leipzig','SC Freiburg','1.FC Union Berlin','FC Schalke 04','Borussia Mönchengladbach','Eintracht Frankfurt']\n",
    "France = ['AS Monaco','Montpellier HSC','FC Girondins Bordeaux','Paris Saint-Germain','Olympique Marseille','OGC Nice','Nîmes Olympique','FC Nantes','Stade Reims','FC Lorient','Stade Brestois 29','LOSC Lille','Stade Rennais FC','Dijon FCO','RC Strasbourg Alsace','RC Lens','AS Saint-Étienne','FC Metz','Olympique Lyon','SCO Angers']\n",
    "\n",
    "LeagueList = []\n",
    "for a in df['Club']:\n",
    "    if a in England:\n",
    "        LeagueList.append('Premier League')\n",
    "    elif a in Spain:\n",
    "        LeagueList.append('La Liga')\n",
    "    elif a in Italy:\n",
    "        LeagueList.append('Serie A')\n",
    "    elif a in Germany:\n",
    "        LeagueList.append('Bundesliga')\n",
    "    elif a in France:\n",
    "        LeagueList.append('Ligue 1')\n",
    "    else:\n",
    "        LeagueList.append(\"UNKNOWN\")\n",
    "        \n",
    "merged_df['League'] = LeagueList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at our dataframe with contract information appended.\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are some duplicate rows\n",
    "merged_df.drop_duplicates(keep=\"first\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting data to .csv format in the repo's data folder.\n",
    "merged_df.to_csv(r'data/transfermarktMONDAY.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
